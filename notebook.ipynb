{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Based Heart Disease Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project uses 4 databases concerning heart disease diagnosis. Title of the database is ***Heart Disease Databases***.\n",
    "\n",
    "All attributes are numeric-valued.  The data was collected from the four following locations:\n",
    "\n",
    "     1. Cleveland Clinic Foundation (cleveland.data)\n",
    "     2. Hungarian Institute of Cardiology, Budapest (hungarian.data)\n",
    "     3. V.A. Medical Center, Long Beach, CA (long-beach-va.data)\n",
    "     4. University Hospital, Zurich, Switzerland (switzerland.data)\n",
    "\n",
    "Each database has the same instance format.  While the databases have 76 raw attributes, only 14 of them are actually used in this project.\n",
    "\n",
    "The authors of the databases have requested that any publications resulting from the use of the data include the names of the principal investigator responsible for the data collection at each institution.  They would be:\n",
    "\n",
    "       1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\n",
    "       2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\n",
    "       3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\n",
    "       4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D.\n",
    "- Donor: David W. Aha (aha@ics.uci.edu) (714) 856-8779   \n",
    "- Date: July, 1988\n",
    "\n",
    "14 attributes (columns) are used :\n",
    "1. age: age in years     \n",
    "2. sex: sex (1 = male; 0 = female)  \n",
    "3.  cp: chest pain type\n",
    "- Value 1: typical angina\n",
    "- Value 2: atypical angina\n",
    "- Value 3: non-anginal pain\n",
    "- Value 4: asymptomatic\n",
    "4. trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n",
    "5. chol: serum cholestoral in mg/dl\n",
    "6. fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n",
    "7. restecg: resting electrocardiographic results\n",
    "- Value 0: normal\n",
    "- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "8. thalach: maximum heart rate achieved\n",
    "9. exang: exercise induced angina (1 = yes; 0 = no)\n",
    "10. oldpeak = ST depression induced by exercise relative to rest\n",
    "11. slope: the slope of the peak exercise ST segment\n",
    "- Value 1: upsloping\n",
    "- Value 2: flat\n",
    "- Value 3: downsloping\n",
    "12. ca: number of major vessels (0-3) colored by flourosopy\n",
    "13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "14. num: diagnosis of heart disease from 0 (no presence) to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation and Cleaning\n",
    "There are 4 data files from 4 Clinics (Cleveland: 303 rows, Hungarian: 294 rows, Switzerland: 123 rows, and Long Beach VA: 200 rows). Each data file is a text file that contains no column names. Each data is separated by a comma. Each row is ended by a newline. There is a separate description file that describes the name of the 14 columns use in each of this text file and other descriptions about the data.\n",
    "\n",
    "In this preparation stage we will load all this data from 4 separate files, merge them into one data frame, and clean all the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    age  sex   cp trestbps   chol  fbs restecg thalach exang oldpeak slope  \\\n",
       " 0  63.0  1.0  1.0    145.0  233.0  1.0     2.0   150.0   0.0     2.3   3.0   \n",
       " 1  67.0  1.0  4.0    160.0  286.0  0.0     2.0   108.0   1.0     1.5   2.0   \n",
       " 2  67.0  1.0  4.0    120.0  229.0  0.0     2.0   129.0   1.0     2.6   2.0   \n",
       " 3  37.0  1.0  3.0    130.0  250.0  0.0     0.0   187.0   0.0     3.5   3.0   \n",
       " 4  41.0  0.0  2.0    130.0  204.0  0.0     2.0   172.0   0.0     1.4   1.0   \n",
       " \n",
       "     ca thal  num  \n",
       " 0  0.0  6.0    0  \n",
       " 1  3.0  3.0    2  \n",
       " 2  2.0  7.0    1  \n",
       " 3  0.0  3.0    0  \n",
       " 4  0.0  3.0    0  ,\n",
       " (920, 14))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the paths to the newly uploaded files\n",
    "file_paths = [\n",
    "    'data/processed.cleveland.data',\n",
    "    'data/processed.hungarian.data',\n",
    "    'data/processed.switzerland.data',\n",
    "    'data/processed.va.data'\n",
    "]\n",
    "\n",
    "# Using the column names given in the description\n",
    "column_names = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', \n",
    "    'fbs', 'restecg', 'thalach', 'exang', \n",
    "    'oldpeak', 'slope', 'ca', 'thal', 'num'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to hold the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Iterate over each file path, load the data into a DataFrame, and append it to the list\n",
    "for path in file_paths:\n",
    "    df = pd.read_csv(path, header=None, names=column_names).replace('?', pd.NA)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all the DataFrames into one\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "combined_df.head(), combined_df.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataframe by treating the missing values\n",
    "\n",
    "There are 3 steps involved :\n",
    "1. Check which columns have missing values.\n",
    "\n",
    "2. Determine the strategy for each column based on its type and significance.\n",
    "- For categorical columns, replacing missing values with the mode or a special category like 'unknown' might be suitable.\n",
    "- For numerical columns, imputing missing values with the median instead of mean could be appropriate given the clinical significance to minimise the impact of outliers.\n",
    "\n",
    "3. Apply the chosen strategies to handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column with missing values and their respective amount of missing values : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trestbps     59\n",
       "chol         30\n",
       "fbs          90\n",
       "restecg       2\n",
       "thalach      55\n",
       "exang        55\n",
       "oldpeak      62\n",
       "slope       309\n",
       "ca          611\n",
       "thal        486\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which columns have missing values in the uncleaned DataFrame\n",
    "columns_with_missing_values = combined_df.isna().sum()\n",
    "print(\"Column with missing values and their respective amount of missing values : \")\n",
    "columns_with_missing_values[columns_with_missing_values > 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Identifying the columns with missing value***\n",
    "\n",
    "- Categorical columns with missing values are :\n",
    "1. fbs\n",
    "2. restecg\n",
    "3. exang\n",
    "4. slope\n",
    "5. thal\n",
    "6. ca\n",
    "\n",
    "- Numerical columns with missing values are :\n",
    "1. trestbps\n",
    "2. chol\n",
    "3. thalach\n",
    "4. oldpeak"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Treatment for missing values***\n",
    "\n",
    "- Numerical columns missing values were imputed with the median.\n",
    "- Categorical columns missing values were replaced with the mode of their respective columns.\n",
    "- For the columns ca and thal, missing values were replaced with 'unknown' (which is its own separate category) to indicate the absence of data without assuming any clinical value because we have deduced that these 2 columns are very important in the diagnosis and imputing a value may contribute to inaaccurate diagnosis\n",
    "\n",
    "Note : \n",
    "Since ca and thal are essential for diagnoses and can be considered categorical with clinical data , we will treat them carefully, categorizing missing values as 'unknown'.\n",
    "\n",
    "- ca: number of major vessels (0-3) colored by flourosopy\n",
    "- thal: 3 = normal; 6 = fixed defect; 7 = reversable defect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(age         0\n",
       " sex         0\n",
       " cp          0\n",
       " trestbps    0\n",
       " chol        0\n",
       " fbs         0\n",
       " restecg     0\n",
       " thalach     0\n",
       " exang       0\n",
       " oldpeak     0\n",
       " slope       0\n",
       " ca          0\n",
       " thal        0\n",
       " num         0\n",
       " dtype: int64,\n",
       "     age  sex   cp  trestbps   chol  fbs restecg  thalach exang  oldpeak slope  \\\n",
       " 0  63.0  1.0  1.0     145.0  233.0  1.0     2.0    150.0   0.0      2.3   3.0   \n",
       " 1  67.0  1.0  4.0     160.0  286.0  0.0     2.0    108.0   1.0      1.5   2.0   \n",
       " 2  67.0  1.0  4.0     120.0  229.0  0.0     2.0    129.0   1.0      2.6   2.0   \n",
       " 3  37.0  1.0  3.0     130.0  250.0  0.0     0.0    187.0   0.0      3.5   3.0   \n",
       " 4  41.0  0.0  2.0     130.0  204.0  0.0     2.0    172.0   0.0      1.4   1.0   \n",
       " \n",
       "     ca thal  num  \n",
       " 0  0.0  6.0    0  \n",
       " 1  3.0  3.0    2  \n",
       " 2  2.0  7.0    1  \n",
       " 3  0.0  3.0    0  \n",
       " 4  0.0  3.0    0  )"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# Define the list of categorical columns intended for mode imputation\n",
    "categorical_columns_with_mode = ['fbs', 'restecg', 'exang', 'slope']\n",
    "\n",
    "# Define list of numerical columns intended to be imputed with the median\n",
    "numerical_columns = ['trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "numerical_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Convert pd.NA to np.nan for numerical columns again to ensure no issues\n",
    "combined_df[numerical_columns] = combined_df[numerical_columns].apply(lambda col: col.replace(pd.NA, np.nan))\n",
    "\n",
    "# Apply median imputation for numerical columns again to be safe\n",
    "combined_df[numerical_columns] = numerical_imputer.fit_transform(combined_df[numerical_columns])\n",
    "\n",
    "# Replace missing values with 'unknown' for 'ca' and 'thal' columns\n",
    "combined_df['ca'].replace(pd.NA, 'unknown', inplace=True)\n",
    "combined_df['thal'].replace(pd.NA, 'unknown', inplace=True)\n",
    "\n",
    "# For the categorical columns, replace missing values with the mode (now ensuring the variable is defined)\n",
    "for column in categorical_columns_with_mode:\n",
    "    combined_df[column] = combined_df[column].replace(pd.NA, combined_df[column].mode().iloc[0])\n",
    "\n",
    "# Final check for missing values\n",
    "final_missing_values_check_again = combined_df.isnull().sum()\n",
    "final_missing_values_check_again, combined_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "Read all the codes above. Try to understand it. Simply put, the name of the clean dataframe you are working with is called 'combined.df'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>unknown</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs restecg  thalach exang  oldpeak  \\\n",
       "0    63.0  1.0  1.0     145.0  233.0  1.0     2.0    150.0   0.0      2.3   \n",
       "1    67.0  1.0  4.0     160.0  286.0  0.0     2.0    108.0   1.0      1.5   \n",
       "2    67.0  1.0  4.0     120.0  229.0  0.0     2.0    129.0   1.0      2.6   \n",
       "3    37.0  1.0  3.0     130.0  250.0  0.0     0.0    187.0   0.0      3.5   \n",
       "4    41.0  0.0  2.0     130.0  204.0  0.0     2.0    172.0   0.0      1.4   \n",
       "..    ...  ...  ...       ...    ...  ...     ...      ...   ...      ...   \n",
       "915  54.0  0.0  4.0     127.0  333.0    1       1    154.0     0      0.0   \n",
       "916  62.0  1.0  1.0     130.0  139.0    0       1    140.0     0      0.5   \n",
       "917  55.0  1.0  4.0     122.0  223.0    1       1    100.0     0      0.0   \n",
       "918  58.0  1.0  4.0     130.0  385.0    1       2    140.0     0      0.5   \n",
       "919  62.0  1.0  2.0     120.0  254.0    0       2     93.0     1      0.0   \n",
       "\n",
       "    slope       ca     thal  num  \n",
       "0     3.0      0.0      6.0    0  \n",
       "1     2.0      3.0      3.0    2  \n",
       "2     2.0      2.0      7.0    1  \n",
       "3     3.0      0.0      3.0    0  \n",
       "4     1.0      0.0      3.0    0  \n",
       "..    ...      ...      ...  ...  \n",
       "915     2  unknown  unknown    1  \n",
       "916     2  unknown  unknown    0  \n",
       "917     2  unknown        6    2  \n",
       "918     2  unknown  unknown    0  \n",
       "919     2  unknown  unknown    1  \n",
       "\n",
       "[920 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(920, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(combined_df)\n",
    "combined_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
